import os
import torch
import yaml
from PIL import Image
from transformers import CLIPImageProcessor

# ì‚¬ìš©ì ëª¨ë“ˆ
from models.dpr_net_v2 import DPRNetV2

# ==============================================================================
# âš™ï¸ ì„¤ì •
# ==============================================================================
CONFIG_PATH = "configs/dpr_config.yaml"

# 1. í™•ì¸í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ ê²½ë¡œ (ì•„ê¹Œ ë…¸ì´ì¦ˆ ì‹¬í–ˆë˜ ê·¸ ì´ë¯¸ì§€ ì¶”ì²œ)
TEST_IMAGE_PATH = r"G:\DPR-Net\data\rain100H\train\rain\rain-001.png" 

# 2. í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ê°€ì¥ ìµœê·¼ì— ì €ì¥ëœ ê²ƒ)
# ì˜ˆ: "G:\DPR-Net\logs\checkpoint_epoch_01_loss_....pth"
CHECKPOINT_PATH = r"G:\DPR-Net\logs\checkpoint_epoch_01_loss_0.5716_psnr_6.28_ssim_0.0000.pth" # <-- íŒŒì¼ëª… ìˆ˜ì • í•„ìš”

def load_config(path):
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    print(f"âš™ï¸ Loading Config...")
    config = load_config(CONFIG_PATH)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. ëª¨ë¸ ë¹Œë“œ (4-bit)
    print("ğŸ—ï¸ Loading Model...")
    model = DPRNetV2(config).to(device)
    
    # 2. ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í•™ìŠµëœ ë‡Œ ë¶ˆëŸ¬ì˜¤ê¸°)
    if os.path.exists(CHECKPOINT_PATH):
        print(f"ğŸ“‚ Loading Trained Weights: {CHECKPOINT_PATH}")
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
        # strict=False: í•™ìŠµí•  ë•Œ VETNet íŒŒë¼ë¯¸í„° ë“±ì€ í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ë¬´ê´€í•˜ë¯€ë¡œ ì¼ë¶€ ë¶ˆì¼ì¹˜ í—ˆìš©
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        print("   âœ… Weights Loaded Successfully!")
    else:
        print("   âš ï¸ Checkpoint not found! Using random weights (Just testing logic).")

    model.eval()

    # 3. ì´ë¯¸ì§€ ì¤€ë¹„
    print(f"\nğŸ“¸ Processing Image: {TEST_IMAGE_PATH}")
    clip_processor = CLIPImageProcessor.from_pretrained(config['model']['vision_model_id'])
    
    try:
        raw_image = Image.open(TEST_IMAGE_PATH).convert('RGB')
        pixel_values = clip_processor(images=raw_image, return_tensors="pt").pixel_values.to(device)
    except Exception as e:
        print(f"   âŒ Image load failed: {e}")
        return

    # 4. ì§ˆë¬¸ ë˜ì§€ê¸° (í”„ë¡¬í”„íŠ¸)
    # BLIPì´ ì¼ë˜ ê²ƒê³¼ ë¹„ìŠ·í•œ ì§ˆë¬¸ì„ ë˜ì ¸ì„œ, Mistralì´ í•™ìŠµí•œ ë‚´ìš©ì„ ìœ ë„í•©ë‹ˆë‹¤.
    prompt_text = "Question: Describe the weather conditions and visual defects in this image detailedly. Answer:"
    
    tokenizer = model.brain.tokenizer
    input_ids = tokenizer(prompt_text, return_tensors="pt").input_ids.to(device)

    print(f"ğŸ’¬ Asking Mistral: '{prompt_text}'")
    print("-" * 50)

    # 5. ë‹µë³€ ìƒì„± (Generate)
    with torch.no_grad():
        # dpr_net_v2.pyì— chat_about_image í•¨ìˆ˜ í™œìš©
        # ë‚´ë¶€ì ìœ¼ë¡œ model.brain.generate_captionì„ í˜¸ì¶œí•¨
        
        # ì§ì ‘ brainì˜ generate í˜¸ì¶œ
        # (ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ -> í…ìŠ¤íŠ¸ì™€ ê²°í•© -> ìƒì„±)
        vision_embeds = model.eyes(pixel_values) # CLIP
        
        generated_text_list = model.brain.generate_caption(
            image_embeds=vision_embeds,
            input_ids=input_ids,
            max_new_tokens=100 # ìµœëŒ€ 100ë‹¨ì–´ ìƒì„±
        )
        
    # 6. ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ¤– Mistral's Thought:\n")
    print(f"\"{generated_text_list[0]}\"")
    print("-" * 50)

if __name__ == "__main__":
    main()