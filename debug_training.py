import os
import torch
import yaml
from torch.utils.data import DataLoader
from torchvision.utils import save_image
from tqdm import tqdm

# ì‚¬ìš©ì ëª¨ë“ˆ
from models.dpr_net_v2 import DPRNetV2
from data.dataset import DPRDataset

# ==============================================================================
# âš™ï¸ ì„¤ì •
# ==============================================================================
CONFIG_PATH = "configs/dpr_config.yaml"
# í™•ì¸í•˜ê³  ì‹¶ì€ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
CHECKPOINT_PATH = r"G:\DPR-Net\logs\checkpoint_epoch_04_loss_0.1878_psnr_13.77_ssim_0.3949.pth"
OUTPUT_DIR = "debug_images"

def load_config(path):
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    print(f"âš™ï¸ Loading Config...")
    config = load_config(CONFIG_PATH)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. ëª¨ë¸ ë¡œë“œ
    # (ì°¸ê³ : í˜„ì¬ 4-bit ì½”ë“œê°€ ì ìš©ë˜ì–´ ìˆë‹¤ë©´ 4-bitë¡œ ë¡œë“œë©ë‹ˆë‹¤. 
    # ì²´í¬í¬ì¸íŠ¸ê°€ 16-bitë¼ë©´ strict=Falseë¡œ ì–´ëŒ‘í„°ë§Œ ë¡œë“œí•´ì„œ í™•ì¸í•©ë‹ˆë‹¤.)
    try:
        print("ğŸ—ï¸ Loading Model...")
        model = DPRNetV2(config).to(device)
        
        print(f"ğŸ“‚ Loading Checkpoint: {CHECKPOINT_PATH}")
        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
        
        # í‚¤ ë¶ˆì¼ì¹˜ ë¬´ì‹œí•˜ê³  ë¡œë“œ (ë””ë²„ê¹…ìš©)
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        print("   âœ… Checkpoint loaded (strict=False)")
        
        model.eval()
    except Exception as e:
        print(f"\nâŒ Error loading model: {e}")
        return

    # 2. ë°ì´í„°ì…‹ ë¡œë“œ
    dataset = DPRDataset(
        data_root=config['paths']['root_dir'],
        metadata_file=config['paths']['metadata_file'],
        tokenizer_path=config['model']['llm_model_id'],
        max_length=config['model']['max_length']
    )
    
    # âš¡ [ìˆ˜ì •ëœ ë¶€ë¶„] collate_fnì„ ë°˜ë“œì‹œ ë„£ì–´ì¤˜ì•¼ attention_maskê°€ ìƒì„±ë©ë‹ˆë‹¤!
    loader = DataLoader(
        dataset, 
        batch_size=1, 
        shuffle=False,
        collate_fn=DPRDataset.collate_fn  # <--- ì´ê±° ì¶”ê°€í•¨!
    )

    print("ğŸ“¸ Saving Debug Images...")
    
    with torch.no_grad():
        # autocast ì¶”ê°€ (4-bit ëª¨ë¸ í˜¸í™˜ì„± ìœ„í•´)
        from torch.cuda.amp import autocast
        
        for i, batch in enumerate(tqdm(loader, total=5)):
            if i >= 5: break
            
            pixel_values = batch['pixel_values'].to(device)
            input_ids = batch['input_ids'].to(device)
            attn_mask = batch['attention_mask'].to(device) # ì´ì œ ì—ëŸ¬ ì•ˆ ë‚¨
            vet_input = batch['vet_input'].to(device)
            vet_target = batch['vet_target'].to(device)

            with autocast():
                model_input = {
                    'pixel_values': pixel_values,
                    'input_ids': input_ids,
                    'attention_mask': attn_mask,
                    'high_res_images': vet_input
                }
                output = model(model_input)

            # ê²°ê³¼ ì €ì¥ [Input (Noisy) | Output (Restored) | Target (GT)]
            # ê°’ ë²”ìœ„ 0~1ë¡œ í´ë¨í•‘
            vet_input = torch.clamp(vet_input, 0, 1)
            output = torch.clamp(output, 0, 1)
            vet_target = torch.clamp(vet_target, 0, 1)
            
            combined = torch.cat([vet_input, output, vet_target], dim=3)
            
            save_path = os.path.join(OUTPUT_DIR, f"debug_sample_{i}.png")
            save_image(combined, save_path)
            
    print(f"âœ… Debug images saved to: {os.path.abspath(OUTPUT_DIR)}")
    print("ğŸ‘‰ í´ë”ë¥¼ ì—´ì–´ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”. [ì™¼ìª½:ì…ë ¥ | ê°€ìš´ë°:ê²°ê³¼ | ì˜¤ë¥¸ìª½:ì •ë‹µ]")

if __name__ == "__main__":
    main()