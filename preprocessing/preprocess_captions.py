import os
import json
import torch
from PIL import Image
from tqdm import tqdm
from transformers import Blip2Processor, Blip2ForConditionalGeneration

# ==============================================================================
# âš™ï¸ CONFIGURATION
# ==============================================================================
DATA_ROOT = r"G:\DPR-Net\data"
OUTPUT_JSON = os.path.join(DATA_ROOT, "metadata_captions.json")

# ì²˜ë¦¬í•  ë°ì´í„°ì…‹ í´ë” ëª©ë¡
TARGET_FOLDERS = [
    "rain100H",    # Rain Removal
    "lol_dataset", # Low-Light Enhancement
    "CSD",         # Cloud/Snow Removal
    "SOTS"         # Dehazing
]

# âœ… ëª…ì„¸ì„œì— ì •ì˜ëœ "ë³µì› ìµœì í™”" í”„ë¡¬í”„íŠ¸
PROMPT_TEXT = "Question: Describe the weather conditions, lighting, and visual defects in this image detailedly. Answer:"

# ëª¨ë¸ ì„¤ì • (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ 'Salesforce/blip2-opt-2.7b' ì‚¬ìš© ê¶Œìž¥)
MODEL_ID = "Salesforce/blip2-opt-2.7b"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ==============================================================================

def setup_blip2():
    """BLIP-2 ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"ðŸš€ Loading BLIP-2 Model ({MODEL_ID}) on {DEVICE}...")
    print("   (This might take a few minutes for the first download)")
    
    processor = Blip2Processor.from_pretrained(MODEL_ID)
    
    # âš¡ FP16(ë°˜ì •ë°€ë„) ë¡œë“œ: ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ
    model = Blip2ForConditionalGeneration.from_pretrained(
        MODEL_ID, 
        torch_dtype=torch.float16 if DEVICE == "cuda" else torch.float32,
        device_map="auto" # ê°€ëŠ¥í•œ ê²½ìš° ìžë™ìœ¼ë¡œ GPU ë¶„ì‚° í• ë‹¹
    )
    
    return processor, model

def generate_caption(processor, model, image_path):
    """ì´ë¯¸ì§€ í•˜ë‚˜ì— ëŒ€í•´ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° RGB ë³€í™˜
        image = Image.open(image_path).convert('RGB')
        
        # ëª¨ë¸ ìž…ë ¥ ìƒì„±
        inputs = processor(images=image, text=PROMPT_TEXT, return_tensors="pt").to(DEVICE, torch.float16)
        
        # ìº¡ì…˜ ìƒì„± (Max tokens: 60 ì •ë„ë¡œ ì œí•œí•˜ì—¬ í•µì‹¬ë§Œ ì¶”ì¶œ)
        generated_ids = model.generate(**inputs, max_new_tokens=60)
        caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
        
        return caption
    except Exception as e:
        print(f"\nâŒ Error processing {image_path}: {e}")
        return None

def get_all_image_paths(root_dir, target_folders):
    """ì§€ì •ëœ í´ë” ë‚´ì˜ 'ì†ìƒëœ ì´ë¯¸ì§€(Input)'ë§Œ ë˜‘ë˜‘í•˜ê²Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')
    image_paths = []
    
    # ðŸš« ì œì™¸í•  í‚¤ì›Œë“œ ëª©ë¡ (ì •ë‹µ ì´ë¯¸ì§€/GT í´ë”ëª…)
    # norain: ë¹„ ì—†ëŠ” ì •ë‹µ
    # high: ë°ì€ ì •ë‹µ (LoL)
    # Gt: Ground Truth (CSD)
    # clear: ì•ˆê°œ ì—†ëŠ” ì •ë‹µ (SOTS)
    # Mask: ë§ˆìŠ¤í¬ íŒŒì¼
    IGNORE_KEYWORDS = ['norain', 'high', 'Gt', 'clear', 'Mask'] 
    
    print(f"ðŸ” Scanning directories in {root_dir}...")
    
    for folder in target_folders:
        full_path = os.path.join(root_dir, folder)
        if not os.path.exists(full_path):
            print(f"   âš ï¸ Warning: Folder not found, skipping: {full_path}")
            continue
            
        for root, dirs, files in os.walk(full_path):
            # í˜„ìž¬ í´ë” ê²½ë¡œ(root)ì— ì œì™¸ í‚¤ì›Œë“œê°€ í•˜ë‚˜ë¼ë„ ìžˆìœ¼ë©´ í†µì§¸ë¡œ ê±´ë„ˆëœ€
            # ì˜ˆ: "G:\...\rain100H\train\norain" -> 'norain'ì´ í¬í•¨ë˜ì–´ ìžˆìœ¼ë¯€ë¡œ Skip
            if any(keyword in root for keyword in IGNORE_KEYWORDS):
                continue

            for file in files:
                if file.lower().endswith(image_extensions):
                    image_paths.append(os.path.join(root, file))
                    
    print(f"   âœ… Found {len(image_paths)} valid input images (filtered GT/Clean images).")
    return image_paths

def main():
    # 1. ëª¨ë¸ ì¤€ë¹„
    processor, model = setup_blip2()
    
    # 2. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¤‘ë‹¨ í›„ ì´ì–´í•˜ê¸° ê¸°ëŠ¥)
    metadata = {}
    if os.path.exists(OUTPUT_JSON):
        print(f"ðŸ“‚ Found existing metadata file: {OUTPUT_JSON}")
        try:
            with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            print(f"   resume from {len(metadata)} processed images.")
        except json.JSONDecodeError:
            print("   âš ï¸ JSON file is corrupted. Starting from scratch.")

    # 3. ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (í•„í„°ë§ ì ìš©ë¨)
    image_files = get_all_image_paths(DATA_ROOT, TARGET_FOLDERS)
    
    # 4. ì²˜ë¦¬ ë£¨í”„
    save_interval = 50 # 50ìž¥ë§ˆë‹¤ ì €ìž¥
    newly_processed_count = 0
    
    print("STARTING CAPTION GENERATION...")
    print("===================================================")
    
    for i, img_path in enumerate(tqdm(image_files)):
        # ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ëŠ” ìŠ¤í‚µ (ê²½ë¡œë¥¼ Keyë¡œ ì‚¬ìš©)
        # Windows ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•´ ì •ê·œí™”
        norm_path = os.path.normpath(img_path)
        
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ì— í‚¤ê°€ ìžˆëŠ”ì§€ í™•ì¸
        if norm_path in metadata or img_path in metadata:
            continue
            
        # ìº¡ì…˜ ìƒì„±
        caption = generate_caption(processor, model, img_path)
        
        if caption:
            metadata[img_path] = caption # ì›ë³¸ ê²½ë¡œë¥¼ Keyë¡œ ì €ìž¥
            newly_processed_count += 1
            
        # ì£¼ê¸°ì  ì €ìž¥
        if newly_processed_count > 0 and newly_processed_count % save_interval == 0:
            with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=4)
                
    # 5. ìµœì¢… ì €ìž¥
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=4)
        
    print("===================================================")
    print(f"ðŸŽ‰ DONE! Metadata saved to: {OUTPUT_JSON}")
    print(f"   Total processed: {len(metadata)}")

if __name__ == "__main__":
    main()