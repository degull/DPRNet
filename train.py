import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from torch.cuda.amp import GradScaler, autocast

# ==============================================================================
# ğŸ§© Custom Modules Import
# í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ëª¨ë“ˆë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ==============================================================================
from models.dpr_net_v2 import DPRNetV2
from data.dataset import DPRDataset

# ==============================================================================
# âš™ï¸ Configuration Path
# ==============================================================================
CONFIG_PATH = "configs/dpr_config.yaml"

def load_config(path):
    """YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(path):
        raise FileNotFoundError(f"Configuration file not found at {path}")
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def save_checkpoint(model, optimizer, epoch, loss, save_dir):
    """í•™ìŠµ ì¤‘ê°„ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        
    save_path = os.path.join(save_dir, f"checkpoint_epoch_{epoch}.pth")
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }, save_path)
    print(f"\nğŸ’¾ Checkpoint saved: {save_path}")

def main():
    # --------------------------------------------------------------------------
    # 1. ì´ˆê¸° ì„¤ì • (Setup)
    # --------------------------------------------------------------------------
    print(f"âš™ï¸ Loading Configuration from {CONFIG_PATH}...")
    config = load_config(CONFIG_PATH)
    
    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    device = torch.device(config['system']['device'] if torch.cuda.is_available() else "cpu")
    print(f"   - Device: {device}")
    
    # --------------------------------------------------------------------------
    # 2. ë°ì´í„°ì…‹ & ë¡œë” ì¤€ë¹„ (Data Pipeline)
    # --------------------------------------------------------------------------
    print("ğŸ’¿ Initializing Datasets...")
    dataset = DPRDataset(
        data_root=config['paths']['root_dir'],
        metadata_file=config['paths']['metadata_file'],
        tokenizer_path=config['model']['llm_model_id'],
        max_length=config['model']['max_length']
    )
    
    train_loader = DataLoader(
        dataset, 
        batch_size=config['train']['batch_size'], 
        shuffle=True, 
        num_workers=config['train']['num_workers'],
        collate_fn=DPRDataset.collate_fn, # ì»¤ìŠ¤í…€ ë°°ì²˜ ì‚¬ìš© í•„ìˆ˜
        pin_memory=True
    )
    print(f"   - Total Images: {len(dataset)}")
    print(f"   - Batch Size: {config['train']['batch_size']}")
    
    # --------------------------------------------------------------------------
    # 3. ëª¨ë¸ ì´ˆê¸°í™” (Model Initialization)
    # --------------------------------------------------------------------------
    print("ğŸ—ï¸ Building DPR-Net V2 Model...")
    model = DPRNetV2(config).to(device)
    
    # --------------------------------------------------------------------------
    # 4. Optimizer ì„¤ì • (Parameter Filtering)
    # âš ï¸ ì¤‘ìš”: CLIPê³¼ Mistral ë³¸ì²´ëŠ” Frozen ìƒíƒœì´ë¯€ë¡œ Optimizerì— ë“±ë¡í•˜ë©´ ì•ˆ ë¨.
    # requires_grad=Trueì¸ íŒŒë¼ë¯¸í„°(LoRA, Decoder, FiLM, VETNet)ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    # --------------------------------------------------------------------------
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.AdamW(trainable_params, lr=float(config['train']['learning_rate']), weight_decay=1e-4)
    
    print(f"   - Trainable Parameters: {len(trainable_params)} tensors")
    
    # --------------------------------------------------------------------------
    # 5. Loss & Precision ì„¤ì •
    # --------------------------------------------------------------------------
    # ë³µì› ì‘ì—…(Restoration)ì—ëŠ” L1 Loss(MAE)ê°€ ê°€ì¥ íš¨ê³¼ì ì´ê³  ì•ˆì •ì ì„
    criterion = nn.L1Loss()
    
    # Mixed Precision (FP16) - ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ
    scaler = GradScaler()
    
    # Gradient Accumulation - ì ì€ ë°°ì¹˜ë¡œ í° ë°°ì¹˜ í•™ìŠµ íš¨ê³¼ë¥¼ ëƒ„
    accum_steps = config['train']['accumulate_grad_batches']
    
    # --------------------------------------------------------------------------
    # 6. í•™ìŠµ ë£¨í”„ (Training Loop)
    # --------------------------------------------------------------------------
    print("\nğŸš€ STARTING TRAINING ğŸš€")
    print("="*60)
    
    num_epochs = config['train']['num_epochs']
    
    for epoch in range(1, num_epochs + 1):
        model.train() # í•™ìŠµ ëª¨ë“œ ì „í™˜
        epoch_loss = 0.0
        
        # tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch}/{num_epochs}")
        
        for step, batch in enumerate(progress_bar):
            # (A) ë°ì´í„° GPUë¡œ ì´ë™
            pixel_values = batch['pixel_values'].to(device)       # CLIP ì…ë ¥
            input_ids = batch['input_ids'].to(device)             # Mistral ì…ë ¥
            attn_mask = batch['attention_mask'].to(device)        # Mistral ë§ˆìŠ¤í¬
            vet_input = batch['vet_input'].to(device)             # VETNet ì…ë ¥ (Noisy Image)
            vet_target = batch['vet_target'].to(device)           # ì •ë‹µ (Ground Truth)
            
            # (B) Forward Pass (AutoCast ì ìš©)
            # autocast ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œëŠ” ìë™ìœ¼ë¡œ FP16/FP32 ì—°ì‚°ì„ ì„ì–´ì”€
            with autocast():
                # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
                model_input = {
                    'pixel_values': pixel_values,
                    'input_ids': input_ids,
                    'attention_mask': attn_mask,
                    'high_res_images': vet_input
                }
                
                # ì˜ˆì¸¡ ê²°ê³¼ (Restored Image)
                restored_images = model(model_input)
                
                # Loss ê³„ì‚° (ì˜ˆì¸¡ vs ì •ë‹µ)
                loss = criterion(restored_images, vet_target)
                
                # Gradient Accumulationì„ ìœ„í•´ Lossë¥¼ ë‚˜ëˆ”
                loss = loss / accum_steps

            # (C) Backward Pass
            # scalerë¥¼ ì‚¬ìš©í•˜ì—¬ Loss ìŠ¤ì¼€ì¼ë§ í›„ ì—­ì „íŒŒ (Underflow ë°©ì§€)
            scaler.scale(loss).backward()
            
            # (D) Optimization Step (Accumulation ì¡°ê±´ ë§Œì¡± ì‹œ)
            if (step + 1) % accum_steps == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad() # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
            
            # (E) Logging
            # ë³´ì—¬ì¤„ ë•ŒëŠ” ë‹¤ì‹œ ìŠ¤ì¼€ì¼ì„ ë³µêµ¬í•´ì„œ í‘œì‹œ
            current_loss = loss.item() * accum_steps
            epoch_loss += current_loss
            progress_bar.set_postfix({'loss': f"{current_loss:.4f}"})
        
        # Epoch ì¢…ë£Œ í›„ í‰ê·  Loss ì¶œë ¥
        avg_loss = epoch_loss / len(train_loader)
        print(f"ğŸ“Š Epoch {epoch} Done. Average Loss: {avg_loss:.5f}")
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        save_checkpoint(model, optimizer, epoch, avg_loss, config['paths']['log_dir'])
        print("-" * 60)
    
    print("ğŸ Training Finished Successfully!")

if __name__ == "__main__":
    main()