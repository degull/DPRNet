# ë‡Œ -> ê³µê°„ ë³€í™˜ (Pixel Decoder)
import torch
import torch.nn as nn
import torch.nn.functional as F

# ==============================================================================
# ğŸ§© The Brain Part 2: Optimized Pixel Decoder
# ì—­í• : LLMì˜ ì¶”ìƒì ì¸ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ í˜¼í•© ì‚¬ê³ ë¥¼ ë‹¤ì‹œ 'ê³µê°„ì (Spatial)'ì¸ ë§µìœ¼ë¡œ ë³€í™˜
# í•µì‹¬: Reshape -> Bottleneck -> PPM(Context) -> Restoration -> Fusion
# ==============================================================================

class PixelDecoder(nn.Module):
    def __init__(self, input_dim=4096, hidden_dim=512, output_dim=4096):
        """
        Args:
            input_dim: Mistral Hidden Size (4096)
            hidden_dim: Bottleneck Channel (512) - ì—°ì‚°ëŸ‰ ê°ì†Œìš©
            output_dim: Final Feature Size (4096) - ë‹¤ì‹œ Mistral ì°¨ì›ìœ¼ë¡œ ë³µêµ¬
        """
        super().__init__()
        
        # 1. Bottleneck (Down-projection)
        # [B, 4096, 16, 16] -> [B, 512, 16, 16]
        # ì±„ë„ì„ 1/8ë¡œ ì¤„ì—¬ ì—°ì‚° íš¨ìœ¨ì„±ì„ í™•ë³´í•˜ê³  íŠ¹ì§•ì„ ì••ì¶•í•©ë‹ˆë‹¤.
        self.bottleneck = nn.Sequential(
            nn.Conv2d(input_dim, hidden_dim, kernel_size=1, bias=False),
            nn.GroupNorm(32, hidden_dim), # í•™ìŠµ ì•ˆì •ì„±ì„ ìœ„í•´ GroupNorm ì‚¬ìš©
            nn.GELU()
        )
        
        # 2. Refined PPM (Pyramid Pooling Module)
        # ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼(1x1, 2x2, 4x4, 8x8)ë¡œ ì´ë¯¸ì§€ë¥¼ ë´ì„œ ë¬¸ë§¥ ì •ë³´ë¥¼ ìˆ˜ì§‘
        self.ppm_scales = [1, 2, 4, 8]
        self.ppm_pooling = nn.ModuleList([
            nn.AdaptiveAvgPool2d(scale) for scale in self.ppm_scales
        ])
        
        # ê° ìŠ¤ì¼€ì¼ë³„ íŠ¹ì§•ì„ ì²˜ë¦¬í•  ì‘ì€ Conv
        self.ppm_convs = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(hidden_dim, hidden_dim // 4, kernel_size=1),
                nn.GELU()
            ) for _ in range(len(self.ppm_scales))
        ])
        
        # 3. Spatial Conv (Feature Aggregation)
        # Original Bottleneck (512) + 4 PPM Scales (128 * 4 = 512) = 1024 Channels
        self.spatial_conv = nn.Sequential(
            nn.Conv2d(hidden_dim + (hidden_dim // 4) * len(self.ppm_scales), hidden_dim, 
                      kernel_size=3, padding=1, bias=False),
            nn.GroupNorm(32, hidden_dim),
            nn.GELU()
        )
        
        # 4. Restoration (Up-projection)
        # [B, 512, 16, 16] -> [B, 4096, 16, 16]
        self.restore = nn.Conv2d(hidden_dim, output_dim, kernel_size=1)
        
        # 5. Final Normalization
        self.final_norm = nn.LayerNorm(output_dim)

    def forward(self, llm_hidden_state):
        """
        Args:
            llm_hidden_state: [Batch, 257 + Text_Len, 4096] (Mistralì˜ ì „ì²´ ì¶œë ¥)
            
        Returns:
            vision_features: [Batch, 257, 4096] (ê³µê°„ ì •ë³´ê°€ ë³µì›ëœ Vision í† í°ë“¤)
        """
        # ----------------------------------------------------------------------
        # Step 1: Token Slicing (Vision Part Extraction)
        # ëª…ì„¸ì„œ: "ë’¤ì— ë¶™ì€ í…ìŠ¤íŠ¸ í† í°ì€ ë²„ë¦¬ê³ , ì•ìª½ 257ê°œë§Œ ì˜ë¼ëƒ…ë‹ˆë‹¤."
        # ----------------------------------------------------------------------
        vision_tokens = llm_hidden_state[:, :257, :] # [B, 257, 4096]
        
        # CLS(ì „ì—­ ì •ë³´)ì™€ Patch(ì§€ì—­ ì •ë³´) ë¶„ë¦¬
        cls_token = vision_tokens[:, 0:1, :]   # [B, 1, 4096]
        patch_tokens = vision_tokens[:, 1:, :] # [B, 256, 4096]
        
        B, N, C = patch_tokens.shape
        H = W = int(N ** 0.5) # 16 (16x16 = 256)
        
        # ----------------------------------------------------------------------
        # Step 2: Reshape to Spatial Map
        # 1D Sequence -> 2D Image Map ë³€í™˜
        # [B, 256, 4096] -> [B, 4096, 256] -> [B, 4096, 16, 16]
        # ----------------------------------------------------------------------
        x = patch_tokens.transpose(1, 2).reshape(B, C, H, W)
        
        # ----------------------------------------------------------------------
        # Step 3: Bottleneck & PPM (Context Enhancement)
        # ----------------------------------------------------------------------
        x_bn = self.bottleneck(x) # [B, 512, 16, 16]
        
        ppm_outs = [x_bn]
        for pool, conv in zip(self.ppm_pooling, self.ppm_convs):
            feat = pool(x_bn)
            feat = conv(feat)
            # âš ï¸ Key Update: Bilinear Interpolation (align_corners=False)
            # ì‘ì€ ë§µì„ ë‹¤ì‹œ 16x16ìœ¼ë¡œ í‚¤ìš¸ ë•Œ ê²©ì ë¬´ëŠ¬ ë°©ì§€
            feat = F.interpolate(feat, size=(H, W), mode='bilinear', align_corners=False)
            ppm_outs.append(feat)
            
        # Concatenation: 512 + (128*4) = 1024 channels
        x_ppm = torch.cat(ppm_outs, dim=1) 
        
        # ----------------------------------------------------------------------
        # Step 4: Spatial Convolution & Restoration
        # ----------------------------------------------------------------------
        x_spatial = self.spatial_conv(x_ppm) # [B, 512, 16, 16]
        x_restored = self.restore(x_spatial) # [B, 4096, 16, 16]
        
        # ----------------------------------------------------------------------
        # Step 5: Flatten & Feature Fusion
        # ë‹¤ì‹œ í† í° í˜•íƒœë¡œ ë³€í™˜: [B, 4096, 16, 16] -> [B, 256, 4096]
        # ----------------------------------------------------------------------
        x_flat = x_restored.flatten(2).transpose(1, 2)
        
        # 1. Residual Connection (Skip Connection)
        # ì›ë˜ì˜ patch_tokensì— ì²˜ë¦¬ëœ ì •ë³´(x_flat)ë¥¼ ë”í•¨ -> í•™ìŠµ ì•ˆì •ì„±
        refined_patches = patch_tokens + x_flat
        
        # 2. Global Context Fusion (Broadcasting)
        # CLS í† í°(ì´ë¯¸ì§€ ì „ì²´ ìš”ì•½)ì„ ëª¨ë“  íŒ¨ì¹˜ í”½ì…€ì— ë”í•´ì¤Œ
        refined_patches = refined_patches + cls_token
        
        # ----------------------------------------------------------------------
        # Step 6: Final Assembly
        # CLS í† í°ê³¼ ì •ì œëœ íŒ¨ì¹˜ë¥¼ ë‹¤ì‹œ í•©ì¹¨
        # ----------------------------------------------------------------------
        out = torch.cat([cls_token, refined_patches], dim=1) # [B, 257, 4096]
        
        # ìµœì¢… ì •ê·œí™”
        out = self.final_norm(out)
        
        return out