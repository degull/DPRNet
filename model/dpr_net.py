# G:\DPR-Net\model\dpr_net.py

import torch
import torch.nn as nn
import torch.nn.functional as F
# 'torchvision'ì€ CLIP ì •ê·œí™”ë¥¼ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤. (pip install torchvision)
import torchvision.transforms as T 

# --- 1. ëª¨ë“ˆ ì„í¬íŠ¸ ---

# VETNet (Hands) ë°±ë³¸ ë° êµ¬ì„±ìš”ì†Œ
# (RestormerVolterraê°€ Encoder, Decoder ë“±ì„ exportí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
#  ìƒì†(inheritance)ì„ ì‚¬ìš©í•´ forward passë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤.)
from .restormer_volterra import RestormerVolterra

# DPR-Net V2 ëª¨ë“ˆ (Eyes, Brain, Controller)
from .dpr_modules import DprClipEncoder, DprLLM, DprMultiStageFiLMHead
# í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ LLM ëª¨ë“ˆ
from .dpr_modules import DummyDprLLM 


# -----------------------------------------------
#  â‘¤ FiLMì´ ì£¼ì…ë˜ëŠ” VETNet (Hands)
# -----------------------------------------------

class FiLMedVETNet(RestormerVolterra):
    """
    DPR-Netì˜ FiLM ì‹ í˜¸ë¥¼ ì£¼ì…ë°›ë„ë¡
    ê¸°ì¡´ RestormerVolterra(VETNet)ì˜ forward passë¥¼
    ìˆ˜ì •í•œ LLM ì œì–´í˜• ë°±ë³¸ ëª¨ë“ˆì…ë‹ˆë‹¤.
    
    (ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ëª¨ë“  init ë¡œì§ì„ ìƒì†ë°›ìŠµë‹ˆë‹¤.)
    """
    def __init__(self, *args, **kwargs):
        # ë¶€ëª¨ í´ë˜ìŠ¤(RestormerVolterra)ì˜ __init__ì„ ê·¸ëŒ€ë¡œ í˜¸ì¶œ
        super().__init__(*args, **kwargs)
        print("FiLMedVETNet (Hands): Initialized (inherits from RestormerVolterra).")

    def _apply_film(self, x, film_signal):
        """ FiLM ì‹ í˜¸ (gamma, beta)ë¥¼ í”¼ì²˜ë§µ(x)ì— ì ìš© """
        if film_signal is None:
            # í˜¹ì‹œ ëª¨ë¥¼ ìƒí™© ëŒ€ë¹„ (ì‹ í˜¸ê°€ ì—†ìœ¼ë©´ x ê·¸ëŒ€ë¡œ ë°˜í™˜)
            return x
        
        gamma, beta = film_signal
        
        # V2 ì•„í‚¤í…ì²˜: F_i_out = F_i * Î³_i + Î²_i
        # (Restormerì˜ skip-connectionê³¼ ìœ ì‚¬í•˜ê²Œ, 1 + gammaë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ)
        # return x * (1 + gamma) + beta 
        return x * gamma + beta

    # *** VETNet(RestormerVolterra)ì˜ Forward Pass ì˜¤ë²„ë¼ì´ë“œ ***
    def forward(self, x, film_signals: dict):
        """
        Args:
            x (torch.Tensor): ì…ë ¥ ì´ë¯¸ì§€ (B, C, H, W)
            film_signals (dict): DprMultiStageFiLMHeadì—ì„œ ìƒì„±ëœ
                                 ìŠ¤í…Œì´ì§€ë³„ (gamma, beta) íŠœí”Œ ë”•ì…”ë„ˆë¦¬.
        """
        
        # --- Encoder Path (FiLM ì£¼ì…) ---
        x1 = self.patch_embed(x)
        
        # Encoder 1
        x2 = self.encoder1(x1)
        x2 = self._apply_film(x2, film_signals.get('encoder1'))

        # Encoder 2
        x3 = self.encoder2(self.down1(x2))
        x3 = self._apply_film(x3, film_signals.get('encoder2'))

        # Encoder 3
        x4 = self.encoder3(self.down2(x3))
        x4 = self._apply_film(x4, film_signals.get('encoder3'))
        
        # Latent
        x5 = self.latent(self.down3(x4))
        x5 = self._apply_film(x5, film_signals.get('latent'))

        # --- Decoder Path (FiLM ì£¼ì…) ---
        
        # Decoder 3
        x6 = self.decoder3(self._pad_and_add(self.up3(x5), x4))
        x6 = self._apply_film(x6, film_signals.get('decoder3'))
        
        # Decoder 2
        x7 = self.decoder2(self._pad_and_add(self.up2(x6), x3))
        x7 = self._apply_film(x7, film_signals.get('decoder2'))
        
        # Decoder 1
        x8 = self.decoder1(self._pad_and_add(self.up1(x7), x2))
        x8 = self._apply_film(x8, film_signals.get('decoder1'))
        
        # Refinement
        x9 = self.refinement(x8)
        x9 = self._apply_film(x9, film_signals.get('refinement'))
        
        # Final output
        # (ì›ë³¸ VETNetê³¼ ë™ì¼í•˜ê²Œ residual connection ì ìš©)
        out = self.output(x9 + x1)
        
        return out


# -----------------------------------------------
#  ğŸš€ DPR-Net (V2) ìµœì¢… ì¡°ë¦½ ëª¨ë¸
# -----------------------------------------------

class DPR_Net(nn.Module):
    """
    DPR-Net (V2) - Dual-Path Restoration Network
    ëª¨ë“  ëª¨ë“ˆ(Eyes, Brain, Controller, Hands)ì„ ì¡°ë¦½í•œ
    ìµœì¢… ì—”ë“œ-íˆ¬-ì—”ë“œ ëª¨ë¸ì…ë‹ˆë‹¤.
    """
    def __init__(self, 
                 # VETNet Backbone Config (restormer_volterra.py ê¸°ë³¸ê°’)
                 vetnet_dim=48, 
                 vetnet_num_blocks=[4,6,6,8],
                 vetnet_refinement_blocks=4,
                 vetnet_heads=[1,2,4,8],
                 vetnet_ffn_exp=2.66,
                 vetnet_bias=False,
                 vetnet_ln_type='WithBias',
                 vetnet_volterra_rank=4,
                 
                 # CLIP Config (dpr_modules.py ê¸°ë³¸ê°’)
                 clip_model_name="ViT-L-14",
                 clip_pretrained="laion2b_s32b_b82k",
                 clip_embed_dim=1024, # ViT-L-14 default
                 
                 # LLM Config (dpr_modules.py ê¸°ë³¸ê°’)
                 llm_model_name="mistralai/Mistral-7B-v0.1",
                 llm_embed_dim=4096 # Mistral-7B default
                ):
        super().__init__()
        
        print("Initializing DPR-Net (V2)...")
        
        # --- 1. Eyes (CLIP) ---
        print("  (1/4) Loading Eyes (CLIP)...")
        self.clip_encoder = DprClipEncoder(
            model_name=clip_model_name,
            pretrained=clip_pretrained
        )
        # CLIPì´ ìš”êµ¬í•˜ëŠ” 224x224 ì •ê·œí™” (ëª¨ë¸ ë‚´ë¶€ì— í¬í•¨)
        clip_mean = (0.48145466, 0.4578275, 0.40821073)
        clip_std = (0.26862954, 0.26130258, 0.27577711)
        self.clip_normalize = T.Normalize(mean=clip_mean, std=clip_std)
        
        # --- 2. Brain (LLM) ---
        print("  (2/4) Loading Brain (LLM)...")
        self.llm_module = DprLLM(
            clip_embed_dim=clip_embed_dim,
            llm_embed_dim=llm_embed_dim,
            model_name=llm_model_name
        )
        self.tokenizer = self.llm_module.tokenizer # for text generation

        # --- 3. Controller (FiLM Head) ---
        print("  (3/4) Loading Controller (FiLM Head)...")
        self.film_head = DprMultiStageFiLMHead(
            llm_embed_dim=llm_embed_dim,
            vetnet_dim=vetnet_dim
        )
        
        # --- 4. Hands (FiLM-Controlled VETNet) ---
        print("  (4/4) Loading Hands (FiLMed VETNet Backbone)...")
        self.vet_backbone = FiLMedVETNet(
            dim=vetnet_dim,
            num_blocks=vetnet_num_blocks,
            num_refinement_blocks=vetnet_refinement_blocks,
            heads=vetnet_heads,
            ffn_expansion_factor=vetnet_ffn_exp,
            bias=vetnet_bias,
            LayerNorm_type=vetnet_ln_type,
            volterra_rank=vetnet_volterra_rank
        )
        
        print("\nâœ… DPR-Net (V2) successfully initialized.")

    def forward(self, img_distorted):
        """
        DPR-Netì˜ V2 ë“€ì–¼-íŒ¨ìŠ¤ forwardë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            img_distorted (torch.Tensor): (B, 3, H, W) 
                                        ì›ë³¸ í•´ìƒë„ì˜ 0~1 ë²”ìœ„ í…ì„œ.
        
        Returns:
            dict: {
                'img_restored': (B, 3, H, W) - ë³µì›ëœ ì´ë¯¸ì§€,
                'logits': (B, N+1, Vocab) - Text Path V2 (L_consistency, Text genìš©),
                'hidden_state': (B, N+1, D_llm) - Control Path V2 (L_consistencyìš©),
                'film_signals': (dict) - VETNetì— ì£¼ì…ëœ (gamma, beta) ë”•ì…”ë„ˆë¦¬
            }
        """
        
        # --- (A) Control/Text Path (LLM) ---
        
        # 1. Preprocess for CLIP (Resize to 224x224, Normalize)
        img_clip = F.interpolate(img_distorted, 
                                 size=224, 
                                 mode='bicubic', 
                                 align_corners=False)
        img_clip_norm = self.clip_normalize(img_clip)
        
        # 2. Eyes -> Brain -> Controller
        vision_tokens, _ = self.clip_encoder(img_clip_norm)
        hidden_state, logits = self.llm_module(vision_tokens)
        film_signals = self.film_head(hidden_state) 
        
        # --- (B) Restoration Path (VETNet) ---
        
        # 3. Hands (VETNet)
        # ì›ë³¸ í•´ìƒë„ ì´ë¯¸ì§€(img_distorted)ì™€ FiLM ì‹ í˜¸(film_signals)ë¥¼ VETNetì— ì£¼ì…
        img_restored = self.vet_backbone(img_distorted, film_signals)
        
        # --- (C) Outputs ---
        
        # V2 í›ˆë ¨(L_total) ë° ì¶”ë¡ (Image+Text)ì— í•„ìš”í•œ ëª¨ë“  ì¶œë ¥ì„ ë°˜í™˜
        return {
            'img_restored': img_restored,  # L_img
            'logits': logits,              # L_consistency, L_text
            'hidden_state': hidden_state,  # L_consistency
            'film_signals': film_signals   # L_film (stage alignment)
        }


# -----------------------------------------------
#  âœ… í…ŒìŠ¤íŠ¸ ì½”ë“œ (dpr_net.py)
# -----------------------------------------------

class DummyDPR_Net(DPR_Net):
    """
    Mistral-7B ë‹¤ìš´ë¡œë“œ ì—†ì´ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ
    DPR_Netì˜ ë”ë¯¸ ë²„ì „ì…ë‹ˆë‹¤.
    """
    def __init__(self, *args, **kwargs):
        # `DPR_Net`ì˜ __init__ì„ í˜¸ì¶œí•˜ë˜,
        # `DprLLM` ë¡œë”© ë¶€ë¶„ì„ `DummyDprLLM`ìœ¼ë¡œ ë®ì–´ì”ë‹ˆë‹¤.
        
        # 1. VETNet/CLIP/FiLMHead config
        vetnet_dim = kwargs.get('vetnet_dim', 48)
        clip_embed_dim = kwargs.get('clip_embed_dim', 1024)
        llm_embed_dim = kwargs.get('llm_embed_dim', 4096)
        
        # `nn.Module.__init__`ì„ ë¨¼ì € í˜¸ì¶œ
        nn.Module.__init__(self) 
        
        print("[Dummy Mode] Initializing DPR-Net (V2)...")
        
        # --- 1. Eyes (CLIP) ---
        print("  (1/4) [Dummy Mode] Loading Eyes (CLIP)...")
        self.clip_encoder = DprClipEncoder(
            model_name=kwargs.get('clip_model_name', "ViT-L-14"),
            pretrained=kwargs.get('clip_pretrained', "laion2b_s32b_b82k")
        )
        clip_mean = (0.48145466, 0.4578275, 0.40821073)
        clip_std = (0.26862954, 0.26130258, 0.27577711)
        self.clip_normalize = T.Normalize(mean=clip_mean, std=clip_std)
        
        # --- 2. Brain (LLM) ---
        print("  (2/4) [Dummy Mode] Loading Brain (Dummy LLM)...")
        self.llm_module = DummyDprLLM( # *** ì—¬ê¸°ê°€ ë‹¤ë¦„ ***
            clip_embed_dim=clip_embed_dim,
            llm_embed_dim=llm_embed_dim
        )
        self.tokenizer = self.llm_module.tokenizer

        # --- 3. Controller (FiLM Head) ---
        print("  (3/4) [Dummy Mode] Loading Controller (FiLM Head)...")
        self.film_head = DprMultiStageFiLMHead(
            llm_embed_dim=llm_embed_dim,
            vetnet_dim=vetnet_dim
        )
        
        # --- 4. Hands (FiLM-Controlled VETNet) ---
        print("  (4/4) [Dummy Mode] Loading Hands (FiLMed VETNet Backbone)...")
        self.vet_backbone = FiLMedVETNet(
            dim=vetnet_dim,
            num_blocks=kwargs.get('vetnet_num_blocks', [4,6,6,8]),
            num_refinement_blocks=kwargs.get('vetnet_refinement_blocks', 4),
            heads=kwargs.get('vetnet_heads', [1,2,4,8]),
            ffn_expansion_factor=kwargs.get('vetnet_ffn_exp', 2.66),
            bias=kwargs.get('vetnet_bias', False),
            LayerNorm_type=kwargs.get('vetnet_ln_type', 'WithBias'),
            volterra_rank=kwargs.get('vetnet_volterra_rank', 4)
        )
        
        print("\nâœ… [Dummy Mode] DPR-Net (V2) successfully initialized.")


if __name__ == '__main__':
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # (ViT-L-14 @ 1024 dim -> Mistral @ 4096 dim)
    # (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë°±ë³¸ í¬ê¸°ë¥¼ ì¤„ì„)
    config = {
        'vetnet_dim': 48,
        'vetnet_num_blocks': [2, 2, 2, 2], # Smaller for fast test
        'vetnet_refinement_blocks': 2,
        'vetnet_heads': [1,2,4,8],
        'clip_embed_dim': 1024, # ViT-L-14
        'llm_embed_dim': 4096,  # Mistral-7B
    }
    
    # ì›ë³¸ í•´ìƒë„ (í™€ìˆ˜, ë¹„ëŒ€ì¹­) - VETNet ê°•ì¸ì„± í…ŒìŠ¤íŠ¸
    B, C, H, W = 2, 3, 127, 133
    # 0~1 ë²”ìœ„ì˜ ëœë¤ ì´ë¯¸ì§€ (ì¼ë°˜ì ì¸ ë°ì´í„°ì…‹ ì…ë ¥)
    dummy_image = torch.rand(B, C, H, W).to(device)
    
    print(f"--- DPR-Net (V2) End-to-End Test (on {device}) ---")
    
    try:
        # `DummyDPR_Net`ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë°©ì§€
        model = DummyDPR_Net(**config).to(device)
        model.eval()
        
        print(f"\nInput image shape: {dummy_image.shape}")
        
        with torch.no_grad():
            outputs = model(dummy_image)
        
        print("\n--- Model Output Verification ---")
        print(f"Type of output: {type(outputs)}")
        assert isinstance(outputs, dict)
        
        # 1. img_restored (ë³µì› ì´ë¯¸ì§€)
        print(f"Restored image shape: {outputs['img_restored'].shape}")
        assert outputs['img_restored'].shape == (B, C, H, W) # ì›ë³¸ í•´ìƒë„ ìœ ì§€
        
        # 2. logits (í…ìŠ¤íŠ¸ ê²½ë¡œ)
        # (B, N+1, Vocab) - N+1 = 257 (ViT-L-14 @ 224px)
        num_tokens = 257 
        vocab_size = model.llm_module.config.vocab_size
        print(f"Logits shape: {outputs['logits'].shape}")
        assert outputs['logits'].shape == (B, num_tokens, vocab_size)
        
        # 3. hidden_state (ì œì–´ ê²½ë¡œ)
        # (B, N+1, D_llm)
        llm_dim = config['llm_embed_dim']
        print(f"Hidden state shape: {outputs['hidden_state'].shape}")
        assert outputs['hidden_state'].shape == (B, num_tokens, llm_dim)
        
        # 4. film_signals (ì œì–´ ì‹ í˜¸)
        num_stages = model.film_head.num_stages # 8ê°œ
        print(f"FiLM signals dict size: {len(outputs['film_signals'])}")
        assert len(outputs['film_signals']) == num_stages
        
        print("\nâœ… DPR-Net (V2) End-to-End test passed!")
        
    except ImportError as e:
        print(f"\n[Error] í•„ìš”í•œ ëª¨ë“ˆì„ G:\\DPR-Net\\model\\ í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"Make sure '__init__.py', 'dpr_modules.py', 'restormer_volterra.py' exist.")
        print(f"Details: {e}")
    except Exception as e:
        import traceback
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()